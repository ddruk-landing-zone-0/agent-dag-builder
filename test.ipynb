{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e011512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import re\n",
    "import threading\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import colorlog\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import json\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9829da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler()  # Log to console\n",
    "\n",
    "        # Define color formatter\n",
    "        formatter = colorlog.ColoredFormatter(\n",
    "            \"%(log_color)s%(asctime)s - %(levelname)s ==> %(message)s\",\n",
    "            log_colors={\n",
    "                'DEBUG': 'bold_cyan',\n",
    "                'INFO': 'bold_green',\n",
    "                'WARNING': 'bold_yellow',\n",
    "                'ERROR': 'bold_red',\n",
    "                'CRITICAL': 'bold_red'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374952f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonEnvironmentManager:\n",
    "    def __init__(self, venv_path: str, create_env: bool = False):\n",
    "        self.venv_path = venv_path\n",
    "        if create_env:\n",
    "            self.create_virtualenv()\n",
    "\n",
    "        self.python_bin = os.path.join(venv_path, \"bin\", \"python\") if os.name != \"nt\" else os.path.join(venv_path, \"Scripts\", \"python.exe\")\n",
    "\n",
    "        if not os.path.exists(self.python_bin):\n",
    "            raise FileNotFoundError(f\"Python executable not found in virtualenv: {self.python_bin}\")\n",
    "        LOGGER.info(f\"Using Python from virtual environment: {self.python_bin}\")\n",
    "\n",
    "    def create_virtualenv(self):\n",
    "        if os.path.exists(self.venv_path):\n",
    "            LOGGER.warning(f\"Virtual environment already exists at {self.venv_path}. Skipping creation.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"venv\", self.venv_path])\n",
    "            LOGGER.info(f\"Created virtual environment at {self.venv_path}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            LOGGER.critical(f\"Failed to create virtual environment: {e}\")\n",
    "            raise\n",
    "\n",
    "    def install_dependencies(self, packages):\n",
    "        if isinstance(packages, str):\n",
    "            packages = [packages]\n",
    "\n",
    "        try:\n",
    "            subprocess.check_call([self.python_bin, \"-m\", \"pip\", \"install\"] + packages)\n",
    "            LOGGER.info(f\"Installed dependencies: {packages}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            LOGGER.critical(f\"Failed to install dependencies: {e}\")\n",
    "            raise\n",
    "\n",
    "    def execute_python_code(self, function_body: str, arguments: dict) -> dict:\n",
    "        # Wrap the function in a script with a fixed \"result\" dict output\n",
    "        code = f\"\"\"\n",
    "import json\n",
    "{function_body}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = {json.dumps(arguments)}\n",
    "    result = function(**args)\n",
    "    print(json.dumps(result))\n",
    "\"\"\"\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".py\", delete=False) as f:\n",
    "            script_path = f.name\n",
    "            f.write(code)\n",
    "\n",
    "        try:\n",
    "            process = subprocess.run(\n",
    "                [self.python_bin, script_path],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "\n",
    "            if process.returncode != 0:\n",
    "                LOGGER.critical(f\"Error in subprocess:\\n{process.stderr}\")\n",
    "                raise RuntimeError(f\"Python code failed: {process.stderr}\")\n",
    "\n",
    "            output = process.stdout.strip()\n",
    "            LOGGER.debug(f\"Subprocess output: {output}\")\n",
    "            result = json.loads(output)\n",
    "            result = {str(k): str(v) for k, v in result.items()}\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            LOGGER.critical(f\"Exception during execution: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            os.unlink(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "7a8d2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNode:\n",
    "    def __init__(self, nodeName, systemInstructions, userPrompt, pythonCode, outputSchema, **kwargs):\n",
    "        \n",
    "        self.nodeName = nodeName # str: Name of the node\n",
    "        self.systemInstructions = systemInstructions # str: Instructions for the system or the system prompt\n",
    "        self.userPrompt = userPrompt # str: User prompt or question can include reference to other nodes\n",
    "        self.pythonCode = pythonCode # str: Python code to be executed\n",
    "        self.outputSchema = outputSchema # Dict: Schema for the output of the node. Dictionary to a dictionary with string keys and values\n",
    "        self.kwargs = kwargs # Additional keyword arguments for flexibility\n",
    "\n",
    "        self._validate() # Validate the node's properties\n",
    "        self.id = self.hash() # str: Unique identifier for the node\n",
    "\n",
    "        self._compiled = False # bool: Flag to indicate if the node has been compiled\n",
    "        self._parents = [] # List: Parent nodes\n",
    "        self._children = [] # List: Child nodes\n",
    "\n",
    "        self._inputs = {} # It is a mutable mapping of input names to their values where the keys are the output keys of the parent nodes' outputs\n",
    "        self._outputs = {} # It is a mutable mapping of output names to their values where the keys are the output keys of the current node's outputs\n",
    "\n",
    "        self.status = \"pending\" # str: Status of the node, can be \"pending\", \"running\" or \"completed\" or \"waiting\"\n",
    "\n",
    "        if nodeName==\"inputs\":\n",
    "            self.status = \"running\"\n",
    "            self._outputs = {**kwargs}\n",
    "            self.status = \"completed\"\n",
    "    \n",
    "    def _validate(self):\n",
    "        # Validate the node's properties\n",
    "        if not isinstance(self.nodeName, str):\n",
    "            LOGGER.error(\"nodeName must be a string. Location: GraphNode._validate\")\n",
    "            raise ValueError(\"nodeName must be a string\")\n",
    "        if not isinstance(self.systemInstructions, str):\n",
    "            LOGGER.error(\"systemInstructions must be a string. Location: GraphNode._validate\")\n",
    "            raise ValueError(\"systemInstructions must be a string\")\n",
    "        if not isinstance(self.userPrompt, str):\n",
    "            LOGGER.error(\"userPrompt must be a string. Location: GraphNode._validate\")\n",
    "            raise ValueError(\"userPrompt must be a string\")\n",
    "        if not isinstance(self.pythonCode, dict):\n",
    "            LOGGER.error(\"pythonCode must be a dict format with a argument and the function_body as the value. Location: GraphNode._validate\")\n",
    "            raise ValueError(\"pythonCode must be a dict format with a argument and the function_body as the value\")\n",
    "        \n",
    "        if self.pythonCode != {}:\n",
    "            if not isinstance(self.pythonCode.get(\"argument\"), dict):\n",
    "                LOGGER.error(\"pythonCode must have an 'argument' key with a dict value of named arguments. Location: GraphNode._validate\")\n",
    "                raise ValueError(\"pythonCode must have an 'argument' key with a dict value of named arguments\")\n",
    "            if not all(isinstance(k, str) and isinstance(v, str) for k, v in self.pythonCode[\"argument\"].items()):\n",
    "                LOGGER.error(\"pythonCode['argument'] must be a dictionary with string keys and values. Location: GraphNode._validate\")\n",
    "                raise ValueError(\"pythonCode['argument'] must be a dictionary with string keys and values\")\n",
    "            if not isinstance(self.pythonCode.get(\"function_body\"), str):\n",
    "                LOGGER.error(\"pythonCode must have a 'function_body' key with a string value. Location: GraphNode._validate\")\n",
    "                raise ValueError(\"pythonCode must have a 'function_body' key with a string value\")\n",
    "        \n",
    "        if not isinstance(self.outputSchema, dict):\n",
    "            LOGGER.error(\"outputSchema must be a dictionary. Location: GraphNode._validate\")\n",
    "            raise ValueError(\"outputSchema must be a dictionary\")\n",
    "        if not all(isinstance(k, str) and isinstance(v, str) for k, v in self.outputSchema.items()):\n",
    "            LOGGER.error(\"outputSchema must be a dictionary with string keys and values. Location: GraphNode._validate\")\n",
    "            raise ValueError(\"outputSchema must be a dictionary with string keys and values\")\n",
    "        if not isinstance(self.kwargs, dict):\n",
    "            LOGGER.error(\"kwargs must be a dictionary. Location: GraphNode._validate\")\n",
    "            raise ValueError(\"kwargs must be a dictionary\")\n",
    "        for key, value in self.kwargs.items():\n",
    "            if not isinstance(key, str):\n",
    "                LOGGER.error(f\"Key '{key}' in kwargs must be a string. Location: GraphNode._validate\")\n",
    "                raise ValueError(f\"Key '{key}' in kwargs must be a string\")\n",
    "            if not isinstance(value, str):\n",
    "                LOGGER.error(f\"Value '{value}' in kwargs must be a string. Location: GraphNode._validate\")\n",
    "                raise ValueError(f\"Value '{value}' in kwargs must be a string\")\n",
    "            \n",
    "    \n",
    "    def hash(self):\n",
    "        # Generate a hash for the node based on its properties\n",
    "        node_string = f\"{self.nodeName}{self.systemInstructions}{self.userPrompt}{self.pythonCode}{str(self.outputSchema)}{str(self.kwargs)}\"\n",
    "        return hashlib.sha256(node_string.encode()).hexdigest()\n",
    "    \n",
    "    def resolve_parent_nodes(self, nodePool):\n",
    "        self._parents = []\n",
    "        pattern = r'@\\[(\\w+)\\.(\\w+)\\]'\n",
    "        \n",
    "        references = re.findall(pattern, self.systemInstructions)\n",
    "        references += re.findall(pattern, self.userPrompt)\n",
    "        references += re.findall(pattern, self.pythonCode.get(\"function_body\", \"\"))\n",
    "        references += re.findall(pattern, str(self.pythonCode.get(\"argument\", {})))\n",
    "        \n",
    "        for node_name, output_key in references:\n",
    "            self._parents.append([node_name, output_key])\n",
    "            nodePool[node_name]._children.append(self.nodeName)\n",
    "            # Remove duplicates\n",
    "            nodePool[node_name]._children = list(set(nodePool[node_name]._children))\n",
    "            \n",
    "        return self._parents\n",
    "    \n",
    "    def resolve_references(self, input_str, nodePool):\n",
    "        # Replace references in the input string with actual values from the node pool\n",
    "        for node_name, output_key in self._parents:\n",
    "            if node_name in nodePool and output_key in nodePool[node_name].outputSchema:\n",
    "                try:\n",
    "                    # Parent key\n",
    "                    parent_key = nodePool[node_name]._outputs[output_key]\n",
    "                    # Replace the reference with the actual value from the node pool\n",
    "                    input_str = input_str.replace(f\"@[{node_name}.{output_key}]\", parent_key)\n",
    "                    # Add the current node as a child of the referenced node\n",
    "                    if f\"@[{node_name}.{output_key}]\" in input_str:\n",
    "                        self._inputs[f\"@[{node_name}.{output_key}]\"] = parent_key\n",
    "                except Exception as e:\n",
    "                    LOGGER.error(f\"Error replacing reference @{node_name}.{output_key}: {e}. Location: GraphNode.resolve_references\")\n",
    "                    # If there's an error, keep the original string\n",
    "        return input_str\n",
    "    \n",
    "\n",
    "    def get_current_state(self, nodePool):\n",
    "        nodeName = self.nodeName\n",
    "        systemInstructions = self.resolve_references(self.systemInstructions, nodePool)\n",
    "        userPrompt = self.resolve_references(self.userPrompt, nodePool)\n",
    "        pythonCode = self.resolve_references(self.pythonCode.get(\"function_body\", \"\"), nodePool)\n",
    "        argument = self.pythonCode.get(\"argument\", {})\n",
    "        for key, value in argument.items():\n",
    "            argument[key] = self.resolve_references(value, nodePool)\n",
    "        outputs = self._outputs\n",
    "\n",
    "        state = {\n",
    "            \"nodeName\": nodeName,\n",
    "            \"systemInstructions\": systemInstructions,\n",
    "            \"userPrompt\": userPrompt,\n",
    "            \"pythonCode\": {\n",
    "                \"function_body\": pythonCode,\n",
    "                \"argument\": argument\n",
    "            },\n",
    "            \"outputs\": outputs\n",
    "        }\n",
    "\n",
    "        return state\n",
    "\n",
    "    def check_parent_status(self, nodePool):\n",
    "        # Check if all parent nodes are completed\n",
    "        for parent in self._parents:\n",
    "            node_name, output_key = parent\n",
    "            if node_name in nodePool:\n",
    "                parent_node = nodePool[node_name]\n",
    "                if parent_node.status != \"completed\":\n",
    "                    LOGGER.warning(f\"Parent node {node_name} of {self.nodeName} is not completed. Location: GraphNode.check_parent_status\")\n",
    "                    return False\n",
    "            else:\n",
    "                LOGGER.error(f\"Parent node {node_name} not found in node pool. Location: GraphNode.check_parent_status\")\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _validate_output(self, result):\n",
    "        if result is None:\n",
    "            LOGGER.error(\"Result is None. Location: GraphNode._validate_output\")\n",
    "            raise ValueError(\"Result is None.\")\n",
    "        # Validate the output against the output schema\n",
    "        for key, value in self.outputSchema.items():\n",
    "            if key not in result:\n",
    "                LOGGER.error(f\"Output key '{key}' not found in result. Location: GraphNode._validate_output\")\n",
    "                raise ValueError(f\"Output key '{key}' not found in result.\")\n",
    "            if not isinstance(result[key], type(value)):\n",
    "                raise ValueError(f\"Output key '{key}' has incorrect type. Expected {type(value)}, got {type(result[key])}.\")\n",
    "        return True\n",
    "\n",
    "\n",
    "    def execute(self, nodePool, python_env_manager: PythonEnvironmentManager):\n",
    "        if not self.check_parent_status(nodePool):\n",
    "            LOGGER.warning(f\"Parent nodes are not completed for {self.nodeName}. Location: GraphNode.execute\")\n",
    "            return None\n",
    "        self.status = \"running\"\n",
    "        # Execute the Python code with the resolved arguments\n",
    "        state = self.get_current_state(nodePool)\n",
    "        systemInstructions = state[\"systemInstructions\"]\n",
    "        userPrompt = state[\"userPrompt\"]\n",
    "        pythonFunctionBody = state[\"pythonCode\"][\"function_body\"]\n",
    "        pythonCodeArgument = state[\"pythonCode\"][\"argument\"]\n",
    "\n",
    "        if pythonFunctionBody != \"\" and python_env_manager is not None:\n",
    "            # Prepare the arguments for output\n",
    "            result = python_env_manager.execute_python_code(pythonFunctionBody, pythonCodeArgument)\n",
    "            # Check if the result matches the output schema\n",
    "            if not self._validate_output(result):\n",
    "                LOGGER.error(f\"Output does not match the schema for {self.nodeName}. Location: GraphNode.execute\")\n",
    "                return None\n",
    "            # Store the result in _outputs\n",
    "            self._outputs = result\n",
    "        else:\n",
    "            # If no Python code is provided, use the system instructions and user prompt (TODO: Implement this LLM logic)\n",
    "            self._outputs = {\n",
    "                k: f\"LLM/{userPrompt}\" for k, v in self.outputSchema.items()\n",
    "            }\n",
    "            \n",
    "        self.status = \"completed\"\n",
    "        return self._outputs\n",
    "\n",
    "    def to_dict(self):\n",
    "        # Convert the node to a dictionary representation\n",
    "        key_value_pairs = {\n",
    "            \"nodeName\": self.nodeName,\n",
    "            \"systemInstructions\": self.systemInstructions,\n",
    "            \"userPrompt\": self.userPrompt,\n",
    "            \"pythonCode\": self.pythonCode,\n",
    "            \"outputSchema\": self.outputSchema,\n",
    "            \"kwargs\": self.kwargs,\n",
    "            \"id\": self.id,\n",
    "            \"_compiled\": self._compiled,\n",
    "            \"_parents\": self._parents,\n",
    "            \"_children\": self._children,\n",
    "            \"_inputs\": self._inputs,\n",
    "            \"_outputs\": self._outputs,\n",
    "            \"status\": self.status\n",
    "        }\n",
    "\n",
    "        return key_value_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b791b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2025-05-17 22:45:21,312 - WARNING ==> Virtual environment already exists at runner_envs/venv. Skipping creation.\u001b[0m\n",
      "\u001b[1;32m2025-05-17 22:45:21,313 - INFO ==> Using Python from virtual environment: runner_envs/venv/bin/python\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "python_env_manager = PythonEnvironmentManager(venv_path=\"runner_envs/venv\", create_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f20732fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m2025-05-17 22:47:38,053 - DEBUG ==> Subprocess output: {\"caps\": \"AFADFAE\"}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'caps': 'AFADFAE'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_env_manager.execute_python_code(\n",
    "    function_body=\"\"\"\n",
    "def function(arg1):\n",
    "    return {\"caps\":arg1.upper()}\n",
    "\"\"\",\n",
    "    arguments={\"arg1\": \"afadfae\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c87cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, timeout=10, venv_path=None, create_env=False, python_packages=[], save_dir=None):\n",
    "        self.nodePool = {\n",
    "        } # Dictionary to hold all nodes\n",
    "        self.save_dir = save_dir\n",
    "        self.graph_id = None\n",
    "        self.conditions = defaultdict(threading.Condition)\n",
    "        self.lock = threading.Lock()\n",
    "        self.timeout = timeout # Timeout for node execution\n",
    "\n",
    "        self.venv_path = venv_path\n",
    "        self.python_packages = python_packages\n",
    "        self.create_env = create_env\n",
    "\n",
    "        if self.venv_path is not None:\n",
    "            self.python_env_manager = PythonEnvironmentManager(self.venv_path, self.create_env)\n",
    "            if python_packages:\n",
    "                self.python_env_manager.install_dependencies(python_packages)\n",
    "        else:\n",
    "            self.python_env_manager = None\n",
    "\n",
    "    def addInput(self, inputFields):\n",
    "        # Add input fields to the graph\n",
    "        if not isinstance(inputFields, dict):\n",
    "            raise ValueError(\"Input fields must be a dictionary\")\n",
    "        \n",
    "        for key, value in inputFields.items():\n",
    "            if not isinstance(key, str):\n",
    "                LOGGER.error(f\"Key '{key}' in input fields must be a string\")\n",
    "                raise ValueError(f\"Key '{key}' in input fields must be a string\")\n",
    "            if not isinstance(value, str):\n",
    "                LOGGER.error(f\"Value '{value}' in input fields must be a string\")\n",
    "                raise ValueError(f\"Value '{value}' in input fields must be a string\")\n",
    "        \n",
    "        new_node = GraphNode(\"inputs\", \"Input node\", \"Input node\", {}, {**inputFields}, **inputFields)\n",
    "        self.nodePool[\"inputs\"] = new_node\n",
    "        return new_node\n",
    "\n",
    "    def addNode(self, nodeName, systemInstructions, userPrompt, pythonCode, outputSchema, **kwargs):\n",
    "        # Add a new node to the graph\n",
    "        if nodeName in self.nodePool:\n",
    "            raise ValueError(f\"Node with name {nodeName} already exists. Location: Graph.addNode\")\n",
    "        \n",
    "        new_node = GraphNode(nodeName, systemInstructions, userPrompt, pythonCode, outputSchema, **kwargs)\n",
    "        self.nodePool[nodeName] = new_node\n",
    "        return new_node\n",
    "    \n",
    "    def getNode(self, nodeName):\n",
    "        # Retrieve a node from the graph\n",
    "        if nodeName not in self.nodePool:\n",
    "            raise ValueError(f\"Node with name {nodeName} does not exist. Location: Graph.getNode\")\n",
    "        \n",
    "        return self.nodePool[nodeName]\n",
    "    \n",
    "    def compile(self):\n",
    "        # Compile the graph by checking dependencies and setting parent-child relationships\n",
    "        for node in self.nodePool.values():\n",
    "            self.nodePool[node.nodeName].resolve_parent_nodes(self.nodePool)\n",
    "            node._compiled = True\n",
    "\n",
    "        self.check_circular_dependency()\n",
    "\n",
    "        # Gnerate a unique graph ID from the node hashes\n",
    "        node_hashes = [node.hash() for node in self.nodePool.values()]\n",
    "        self.graph_id = hashlib.sha256(\"\".join(node_hashes).encode()).hexdigest()\n",
    "        LOGGER.info(f\"Graph compiled with ID: {self.graph_id}. Location: Graph.compile\")\n",
    "        self.save_graph()\n",
    "        \n",
    "    def check_circular_dependency(self):\n",
    "        # Check for circular dependencies in the graph\n",
    "        visited = set()\n",
    "        stack = set()\n",
    "        def visit(node):\n",
    "            if node in stack:\n",
    "                raise ValueError(f\"Circular dependency detected: {node}. Location: Graph.check_circular_dependency\")\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                stack.add(node)\n",
    "                for child in self.nodePool[node]._children:\n",
    "                    visit(child)\n",
    "                stack.remove(node)\n",
    "        for node in self.nodePool:\n",
    "            if node not in visited:\n",
    "                visit(node)\n",
    "        return True\n",
    "     \n",
    "    \n",
    "    def print_graph(self):\n",
    "        # Print the graph in a readable format\n",
    "        for node in self.nodePool.values():\n",
    "            print(node.to_dict())\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def _execute_node_with_condition(self, node, timeout, involved_nodes):\n",
    "        start_time = time.time()\n",
    "        condition = self.conditions[node.nodeName]\n",
    "\n",
    "        with condition:\n",
    "            while not node.check_parent_status(self.nodePool):\n",
    "                remaining = timeout - (time.time() - start_time)\n",
    "                if remaining <= 0:\n",
    "                    LOGGER.warning(f\"Timeout reached for node {node.nodeName}. Location: Graph._execute_node_with_condition\")\n",
    "                    raise TimeoutError(f\"Node {node.nodeName} timed out.\")\n",
    "                condition.wait(timeout=remaining)\n",
    "\n",
    "        with self.lock:\n",
    "            involved_nodes.add(node.nodeName)\n",
    "            LOGGER.info(f\"Running node: {node.nodeName}. Location: Graph._execute_node_with_condition\")\n",
    "            result = node.execute(self.nodePool, self.python_env_manager)\n",
    "            LOGGER.info(f\"Completed node: {node.nodeName} with result: {result} . Location: Graph._execute_node_with_condition\")\n",
    "\n",
    "        # Notify all waiting threads\n",
    "        for child in node._children:\n",
    "            if self.nodePool[child].check_parent_status(self.nodePool):\n",
    "                with self.lock:\n",
    "                    LOGGER.debug(f\"Notifying child node: {child} . Location: Graph._execute_node_with_condition\")\n",
    "                    with self.conditions[child]:\n",
    "                        self.conditions[child].notify_all()\n",
    "\n",
    "    def _traverse_nodes(self, start_node):\n",
    "        visited = set()\n",
    "        queue = [start_node]\n",
    "        while queue:\n",
    "            current = queue.pop(0)\n",
    "            if current in visited:\n",
    "                continue\n",
    "            visited.add(current)\n",
    "            node = self.nodePool[current]\n",
    "            queue.extend(node._children)\n",
    "        return list(visited)\n",
    "    \n",
    "    def execute_from_node(self, start_node):\n",
    "        # Execute the graph from a specific starting node\n",
    "        if start_node not in self.nodePool:\n",
    "            LOGGER.error(f\"Node with name {start_node} does not exist. Location: Graph.execute_from_node\")\n",
    "            raise ValueError(f\"Node with name {start_node} does not exist.\")\n",
    "        \n",
    "        visited = self._traverse_nodes(start_node)\n",
    "\n",
    "        # Check if all nodes are compiled\n",
    "        for node_name in visited:\n",
    "            node = self.nodePool[node_name]\n",
    "            if not node._compiled:\n",
    "                LOGGER.error(f\"Node {node_name} is not compiled. Location: Graph.execute_from_node\")\n",
    "                raise ValueError(f\"Node {node_name} is not compiled.\")\n",
    "            \n",
    "        # Check if all nodes are completed\n",
    "        for node_name in visited:\n",
    "            node = self.nodePool[node_name]\n",
    "            if node.status == \"running\" or node.status == \"waiting\":\n",
    "                LOGGER.error(f\"Node {node_name} is already running or waiting. Location: Graph.execute_from_node\")  \n",
    "                raise ValueError(f\"Node {node_name} is already running or waiting.\")\n",
    "            node.status = \"pending\"\n",
    "            LOGGER.info(f\"Node {node_name} status set to pending.\")\n",
    "\n",
    "\n",
    "        threads = []\n",
    "        involved_nodes = set()\n",
    "\n",
    "        try:\n",
    "            for node_name in visited:\n",
    "                node = self.nodePool[node_name]\n",
    "                if node.status == \"pending\":\n",
    "                    thread = threading.Thread(target=self._execute_node_with_condition, args=(node, self.timeout, involved_nodes))\n",
    "                    threads.append(thread)\n",
    "                    thread.start()\n",
    "                    LOGGER.info(f\"Thread started for node: {node_name} . Location: Graph.execute_from_node\")\n",
    "            \n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "        except TimeoutError as e:\n",
    "            LOGGER.critical(f\"Timeout error: {e}\")\n",
    "            for node_name in involved_nodes:\n",
    "                node = self.nodePool[node_name]\n",
    "                if node.status == \"running\":\n",
    "                    node.status = \"completed\"\n",
    "                    LOGGER.warning(f\"Node {node_name} status set to completed due to timeout. Location: Graph.execute_from_node\")\n",
    "            for node_name in involved_nodes:\n",
    "                node = self.nodePool[node_name]\n",
    "                if node.status == \"running\":\n",
    "                    node.status = \"completed\"\n",
    "                    LOGGER.warning(f\"Node {node_name} status set to completed due to timeout. Location: Graph.execute_from_node\")\n",
    "            LOGGER.error(f\"Error during execution: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            for node_name in visited:\n",
    "                node = self.nodePool[node_name]\n",
    "                if node.status == \"running\":\n",
    "                    node.status = \"completed\"\n",
    "                    LOGGER.info(f\"Node {node_name} status set to completed. Location: Graph.execute_from_node\")\n",
    "            LOGGER.info(\"Execution completed for all nodes. Location: Graph.execute_from_node\")\n",
    "\n",
    "        self.save_graph()\n",
    "\n",
    "\n",
    "    def save_graph(self):\n",
    "        # Save the graph to a JSON file\n",
    "        if not self.save_dir:\n",
    "            LOGGER.error(\"Save directory is not set. Location: Graph.save_graph\")\n",
    "            raise ValueError(\"Save directory is not set. Location: Graph.save_graph\")\n",
    "        file_path = os.path.join(self.save_dir, f\"graph.json\")\n",
    "        with open(file_path, \"w\") as f:\n",
    "            nodes = {node_name: node.to_dict() for node_name, node in self.nodePool.items()}\n",
    "            json.dump({\"nodes\": nodes, \"venv_path\": self.venv_path, \"python_packages\": self.python_packages}, f, indent=4)\n",
    "        LOGGER.info(f\"Graph saved to {file_path}. Location: Graph.save_graph\")\n",
    "\n",
    "    def load_graph(self):\n",
    "        # Load the graph from a JSON file\n",
    "        file_path = os.path.join(self.save_dir, f\"graph.json\")\n",
    "        try:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                for node_name, node_data in data[\"nodes\"].items():\n",
    "                    node = GraphNode(\n",
    "                        node_data[\"nodeName\"],\n",
    "                        node_data[\"systemInstructions\"],\n",
    "                        node_data[\"userPrompt\"],\n",
    "                        node_data[\"pythonCode\"],\n",
    "                        node_data[\"outputSchema\"],\n",
    "                        **node_data[\"kwargs\"]\n",
    "                    )\n",
    "                    # Set the node's properties\n",
    "                    node._compiled = node_data[\"_compiled\"]\n",
    "                    node._parents = node_data[\"_parents\"]\n",
    "                    node._children = node_data[\"_children\"]\n",
    "                    node._inputs = node_data[\"_inputs\"]\n",
    "                    node._outputs = node_data[\"_outputs\"]\n",
    "                    node.status = node_data[\"status\"]\n",
    "                    \n",
    "                    # Add the node to the node pool\n",
    "                    self.nodePool[node_name] = node\n",
    "\n",
    "                self.venv_path = data.get(\"venv_path\", None)\n",
    "                self.python_packages = data.get(\"python_packages\", [])\n",
    "                self.create_env = data.get(\"create_env\", False)\n",
    "                \n",
    "                if self.venv_path is not None:\n",
    "                    self.python_env_manager = PythonEnvironmentManager(self.venv_path, self.create_env)\n",
    "                    if self.python_packages:\n",
    "                        self.python_env_manager.install_dependencies(self.python_packages)\n",
    "                \n",
    "                LOGGER.info(f\"Graph loaded from {file_path}. Location: Graph.load_graph\")\n",
    "        except FileNotFoundError:\n",
    "            LOGGER.error(f\"Graph file not found: {file_path}. Location: Graph.load_graph\")\n",
    "            raise\n",
    "        except json.JSONDecodeError:\n",
    "            LOGGER.error(f\"Error decoding JSON from file: {file_path}. Location: Graph.load_graph\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            LOGGER.error(f\"Error loading graph: {e}. Location: Graph.load_graph\")\n",
    "            raise\n",
    "        self.compile()\n",
    "        LOGGER.info(f\"Graph compiled after loading from {file_path}. Location: Graph.load_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "2fd4af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"input1\": \"10\",\n",
    "    \"input2\": \"12\",\n",
    "    \"input3\": \"41\"\n",
    "}\n",
    "\n",
    "node1 = GraphNode(\n",
    "    nodeName=\"Node1\",\n",
    "    systemInstructions=\"This is a test system instruction for Node1.\",\n",
    "    userPrompt=\"Calculate the sum of @[inputs.input1] and @[inputs.input2] and @[inputs.input1]^2\",\n",
    "    pythonCode={\n",
    "        \"argument\": {\n",
    "            \"arg1\": \"@[inputs.input1]\",\n",
    "            \"arg2\": \"@[inputs.input2]\"\n",
    "        },\n",
    "        \"function_body\": \"def function(arg1, arg2):\\n    return {'output1': int(arg1) + int(arg2), 'output2': int(arg1)**2}\"\n",
    "    },\n",
    "    outputSchema={\n",
    "        \"output1\": \"This is the output1 of Node1 , sum of input1 and input2\",\n",
    "        \"output2\": \"This is the output2 of Node1 , square of input1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "node2 = GraphNode(\n",
    "    nodeName=\"Node2\",\n",
    "    systemInstructions=\"This is a test system instruction for Node2.\",\n",
    "    userPrompt=\"Calculate the sum of @[Node1.output1] and @[inputs.input3]. And also the sum of @[Node1.output1] * @[inputs.input3]\",\n",
    "    pythonCode={\n",
    "        \"argument\": {\n",
    "            \"arg1\": \"@[Node1.output1]\",\n",
    "            \"arg2\": \"@[inputs.input3]\"\n",
    "        },\n",
    "        \"function_body\": \"import time; \\ndef function(arg1, arg2):\\n    time.sleep(5)\\n    return {'output1': int(arg1) + int(arg2), 'output2': int(arg1) * int(arg2)}\"\n",
    "    },\n",
    "    outputSchema={\n",
    "        \"output1\": \"This is the output1 of Node2 , sum of Node1.output1 and input3\",\n",
    "        \"output2\": \"This is the output2 of Node2 , product of Node1.output1 and input3\"\n",
    "    }\n",
    ")\n",
    "\n",
    "node3 = GraphNode(\n",
    "    nodeName=\"Node3\",\n",
    "    systemInstructions=\"This is a test system instruction for Node3.\",\n",
    "    userPrompt=\"Write summary of @[Node1.output1] = @[inputs.input1] + @[inputs.input2] and @[Node2.output1] = @[Node1.output1] + @[inputs.input3]\",\n",
    "    pythonCode={\n",
    "        \"argument\": {},\n",
    "        \"function_body\": \"\"\n",
    "    },\n",
    "    outputSchema={\n",
    "        \"output1\": \"This is the output1 of Node3\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "8376a97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2025-05-15 17:26:32,836 - WARNING ==> Virtual environment already exists at ./runner_envs/venv. Skipping creation.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:26:32,838 - INFO ==> Using Python from virtual environment: ./runner_envs/venv/bin/python\u001b[0m\n",
      "WARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/debasmitroy/Desktop/programming/ddruk-lz-0/agent-dag-builder/runner_envs/venv/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[1;32m2025-05-15 17:26:33,198 - INFO ==> Installed dependencies: ['numpy']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./runner_envs/venv/lib/python3.9/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "graph = Graph(timeout=10, venv_path=\"./runner_envs/venv\", create_env=True, python_packages=[\"numpy\"], save_dir=\"./saved_graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "0959e404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GraphNode at 0x1180d1640>"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "graph.addInput(inputs)\n",
    "\n",
    "graph.addNode(\n",
    "    nodeName=node1.nodeName,\n",
    "    systemInstructions=node1.systemInstructions,\n",
    "    userPrompt=node1.userPrompt,\n",
    "    pythonCode=node1.pythonCode,\n",
    "    outputSchema=node1.outputSchema\n",
    ")\n",
    "\n",
    "graph.addNode(  \n",
    "    nodeName=node2.nodeName,\n",
    "    systemInstructions=node2.systemInstructions,\n",
    "    userPrompt=node2.userPrompt,\n",
    "    pythonCode=node2.pythonCode,\n",
    "    outputSchema=node2.outputSchema\n",
    ")\n",
    "\n",
    "graph.addNode(\n",
    "    nodeName=node3.nodeName,\n",
    "    systemInstructions=node3.systemInstructions,\n",
    "    userPrompt=node3.userPrompt,\n",
    "    pythonCode=node3.pythonCode,\n",
    "    outputSchema=node3.outputSchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "3804c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 16:23:13,371 - INFO ==> Graph compiled with ID: a657b9dfa40e3ebcac5041a8e0926fa4ab3fbb8c155aa3db60d7c88a321e7418. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:13,373 - INFO ==> Graph saved to ./saved_graphs/graph.json. Location: Graph.save_graph\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "20e27e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodeName': 'inputs', 'systemInstructions': 'Input node', 'userPrompt': 'Input node', 'pythonCode': {}, 'outputSchema': {'input1': '10', 'input2': '12', 'input3': '41'}, 'kwargs': {'input1': '10', 'input2': '12', 'input3': '41'}, 'id': 'cd473f364a683944ed5158877169fa68b50c0b106d523e8f81e48f13759838a8', '_compiled': True, '_parents': [], '_children': ['Node3', 'Node1', 'Node2'], '_inputs': {}, '_outputs': {'input1': '10', 'input2': '12', 'input3': '41'}, 'status': 'completed'}\n",
      "{'nodeName': 'Node1', 'systemInstructions': 'This is a test system instruction for Node1.', 'userPrompt': 'Calculate the sum of @[inputs.input1] and @[inputs.input2] and @[inputs.input1]^2', 'pythonCode': {'argument': {'arg1': '@[inputs.input1]', 'arg2': '@[inputs.input2]'}, 'function_body': \"def function(arg1, arg2):\\n    return {'output1': int(arg1) + int(arg2), 'output2': int(arg1)**2}\"}, 'outputSchema': {'output1': 'This is the output1 of Node1 , sum of input1 and input2', 'output2': 'This is the output2 of Node1 , square of input1'}, 'kwargs': {}, 'id': '8e76776a3311123f1498574b64bb53b36b62a2ebd735a479252f712afacd8067', '_compiled': True, '_parents': [['inputs', 'input1'], ['inputs', 'input2'], ['inputs', 'input1'], ['inputs', 'input1'], ['inputs', 'input2']], '_children': ['Node3', 'Node2'], '_inputs': {}, '_outputs': {}, 'status': 'pending'}\n",
      "{'nodeName': 'Node2', 'systemInstructions': 'This is a test system instruction for Node2.', 'userPrompt': 'Calculate the sum of @[Node1.output1] and @[inputs.input3]. And also the sum of @[Node1.output1] * @[inputs.input3]', 'pythonCode': {'argument': {'arg1': '@[Node1.output1]', 'arg2': '@[inputs.input3]'}, 'function_body': \"import time; \\ndef function(arg1, arg2):\\n    time.sleep(5)\\n    return {'output1': int(arg1) + int(arg2), 'output2': int(arg1) * int(arg2)}\"}, 'outputSchema': {'output1': 'This is the output1 of Node2 , sum of Node1.output1 and input3', 'output2': 'This is the output2 of Node2 , product of Node1.output1 and input3'}, 'kwargs': {}, 'id': '3633edf9e78055fa86c0a4466285d51fb03ca4f06980695295bf4216ea45b8b4', '_compiled': True, '_parents': [['Node1', 'output1'], ['inputs', 'input3'], ['Node1', 'output1'], ['inputs', 'input3'], ['Node1', 'output1'], ['inputs', 'input3']], '_children': ['Node3'], '_inputs': {}, '_outputs': {}, 'status': 'pending'}\n",
      "{'nodeName': 'Node3', 'systemInstructions': 'This is a test system instruction for Node3.', 'userPrompt': 'Write summary of @[Node1.output1] = @[inputs.input1] + @[inputs.input2] and @[Node2.output1] = @[Node1.output1] + @[inputs.input3]', 'pythonCode': {'argument': {}, 'function_body': ''}, 'outputSchema': {'output1': 'This is the output1 of Node3'}, 'kwargs': {}, 'id': '1618e010f3f5acef89f28ebd26506db68d08477d891c889b04bc068280faa3b1', '_compiled': True, '_parents': [['Node1', 'output1'], ['inputs', 'input1'], ['inputs', 'input2'], ['Node2', 'output1'], ['Node1', 'output1'], ['inputs', 'input3']], '_children': [], '_inputs': {}, '_outputs': {}, 'status': 'pending'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.print_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "fa29f242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 16:23:15,391 - INFO ==> Node Node3 status set to pending.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,392 - INFO ==> Node Node1 status set to pending.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,393 - INFO ==> Node Node2 status set to pending.\u001b[0m\n",
      "\u001b[1;33m2025-05-15 16:23:15,393 - WARNING ==> Parent node Node1 of Node3 is not completed. Location: GraphNode.check_parent_status\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,393 - INFO ==> Thread started for node: Node3 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,394 - INFO ==> Running node: Node1. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,394 - INFO ==> Thread started for node: Node1 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;33m2025-05-15 16:23:15,395 - WARNING ==> Parent node Node1 of Node2 is not completed. Location: GraphNode.check_parent_status\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,395 - INFO ==> Thread started for node: Node2 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;36m2025-05-15 16:23:15,419 - DEBUG ==> Subprocess output: {\"output1\": 22, \"output2\": 100}\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,420 - INFO ==> Completed node: Node1 with result: {'output1': '22', 'output2': '100'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;33m2025-05-15 16:23:15,421 - WARNING ==> Parent node Node2 of Node3 is not completed. Location: GraphNode.check_parent_status\u001b[0m\n",
      "\u001b[1;36m2025-05-15 16:23:15,421 - DEBUG ==> Notifying child node: Node2 . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:15,421 - INFO ==> Running node: Node2. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;36m2025-05-15 16:23:20,451 - DEBUG ==> Subprocess output: {\"output1\": 63, \"output2\": 902}\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:20,454 - INFO ==> Completed node: Node2 with result: {'output1': '63', 'output2': '902'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;36m2025-05-15 16:23:20,455 - DEBUG ==> Notifying child node: Node3 . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:20,456 - INFO ==> Running node: Node3. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:20,457 - INFO ==> Completed node: Node3 with result: {'output1': 'LLM/Write summary of 22 = 10 + 12 and 63 = 22 + 41'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:20,458 - INFO ==> Execution completed for all nodes. Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;32m2025-05-15 16:23:20,460 - INFO ==> Graph saved to ./saved_graphs/graph.json. Location: Graph.save_graph\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "graph.execute_from_node(\"Node1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "bc3ca7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 14:26:07,494 - INFO ==> Graph saved to ./saved_graphs/graph_a657b9dfa40e3ebcac5041a8e0926fa4ab3fbb8c155aa3db60d7c88a321e7418.json. Location: Graph.save_graph\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "graph.save_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "688b9f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodeName': 'inputs', 'systemInstructions': 'Input node', 'userPrompt': 'Input node', 'pythonCode': {}, 'outputSchema': {'input1': '10', 'input2': '12', 'input3': '41'}, 'kwargs': {'input1': '10', 'input2': '12', 'input3': '41'}, 'id': 'cd473f364a683944ed5158877169fa68b50c0b106d523e8f81e48f13759838a8', '_compiled': True, '_parents': [], '_children': ['Node3', 'Node1', 'Node2'], '_inputs': {}, '_outputs': {'input1': '10', 'input2': '12', 'input3': '41'}, 'status': 'completed'}\n",
      "{'nodeName': 'Node1', 'systemInstructions': 'This is a test system instruction for Node1.', 'userPrompt': 'Calculate the sum of @[inputs.input1] and @[inputs.input2] and @[inputs.input1]^2', 'pythonCode': {'argument': {'arg1': '10', 'arg2': '12'}, 'function_body': \"def function(arg1, arg2):\\n    return {'output1': int(arg1) + int(arg2), 'output2': int(arg1)**2}\"}, 'outputSchema': {'output1': 'This is the output1 of Node1 , sum of input1 and input2', 'output2': 'This is the output2 of Node1 , square of input1'}, 'kwargs': {}, 'id': '8e76776a3311123f1498574b64bb53b36b62a2ebd735a479252f712afacd8067', '_compiled': True, '_parents': [['inputs', 'input1'], ['inputs', 'input2'], ['inputs', 'input1'], ['inputs', 'input1'], ['inputs', 'input2']], '_children': ['Node3', 'Node2'], '_inputs': {}, '_outputs': {'output1': '22', 'output2': '100'}, 'status': 'completed'}\n",
      "{'nodeName': 'Node2', 'systemInstructions': 'This is a test system instruction for Node2.', 'userPrompt': 'Calculate the sum of @[Node1.output1] and @[inputs.input3]. And also the sum of @[Node1.output1] * @[inputs.input3]', 'pythonCode': {'argument': {'arg1': '22', 'arg2': '41'}, 'function_body': \"import time; \\ndef function(arg1, arg2):\\n    time.sleep(5)\\n    return {'output1': int(arg1) + int(arg2), 'output2': int(arg1) * int(arg2)}\"}, 'outputSchema': {'output1': 'This is the output1 of Node2 , sum of Node1.output1 and input3', 'output2': 'This is the output2 of Node2 , product of Node1.output1 and input3'}, 'kwargs': {}, 'id': '3633edf9e78055fa86c0a4466285d51fb03ca4f06980695295bf4216ea45b8b4', '_compiled': True, '_parents': [['Node1', 'output1'], ['inputs', 'input3'], ['Node1', 'output1'], ['inputs', 'input3'], ['Node1', 'output1'], ['inputs', 'input3']], '_children': ['Node3'], '_inputs': {}, '_outputs': {'output1': '63', 'output2': '902'}, 'status': 'completed'}\n",
      "{'nodeName': 'Node3', 'systemInstructions': 'This is a test system instruction for Node3.', 'userPrompt': 'Write summary of @[Node1.output1] = @[inputs.input1] + @[inputs.input2] and @[Node2.output1] = @[Node1.output1] + @[inputs.input3]', 'pythonCode': {'argument': {}, 'function_body': ''}, 'outputSchema': {'output1': 'This is the output1 of Node3'}, 'kwargs': {}, 'id': '1618e010f3f5acef89f28ebd26506db68d08477d891c889b04bc068280faa3b1', '_compiled': True, '_parents': [['Node1', 'output1'], ['inputs', 'input1'], ['inputs', 'input2'], ['Node2', 'output1'], ['Node1', 'output1'], ['inputs', 'input3']], '_children': [], '_inputs': {}, '_outputs': {'output1': 'LLM/Write summary of 22 = 10 + 12 and 63 = 22 + 41'}, 'status': 'completed'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.print_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed9f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd892dfb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d36bcef",
   "metadata": {},
   "source": [
    "## Loading Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "75a50f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2025-05-15 14:26:08,579 - WARNING ==> Virtual environment already exists at ./runner_envs/venv. Skipping creation.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:26:08,580 - INFO ==> Using Python from virtual environment: ./runner_envs/venv/bin/python\u001b[0m\n",
      "WARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/debasmitroy/Desktop/programming/ddruk-lz-0/agent-dag-builder/runner_envs/venv/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[1;32m2025-05-15 14:26:08,905 - INFO ==> Installed dependencies: ['numpy']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./runner_envs/venv/lib/python3.9/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "loaded_graph = Graph(timeout=10, venv_path=\"./runner_envs/venv\", create_env=True, python_packages=[\"numpy\"], save_dir=\"./saved_graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "ea91c465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 14:26:09,906 - INFO ==> Graph loaded from ./saved_graphs/graph_a657b9dfa40e3ebcac5041a8e0926fa4ab3fbb8c155aa3db60d7c88a321e7418.json. Location: Graph.load_graph\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:26:09,907 - INFO ==> Graph compiled with ID: c10870e23ea1d1e7253ca8e586fb4a6a5fcfc497876ded26f3d141dc61047a18. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:26:09,908 - INFO ==> Graph saved to ./saved_graphs/graph_c10870e23ea1d1e7253ca8e586fb4a6a5fcfc497876ded26f3d141dc61047a18.json. Location: Graph.save_graph\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:26:09,909 - INFO ==> Graph compiled after loading from ./saved_graphs/graph_a657b9dfa40e3ebcac5041a8e0926fa4ab3fbb8c155aa3db60d7c88a321e7418.json. Location: Graph.load_graph\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loaded_graph.load_graph(graph_id=\"a657b9dfa40e3ebcac5041a8e0926fa4ab3fbb8c155aa3db60d7c88a321e7418\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "7ad2ace1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_graph.nodePool[\"Node1\"].status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "01d24175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 14:48:01,030 - INFO ==> Node Node3 status set to pending.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,031 - INFO ==> Node Node1 status set to pending.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,032 - INFO ==> Node Node2 status set to pending.\u001b[0m\n",
      "\u001b[1;33m2025-05-15 14:48:01,032 - WARNING ==> Parent node Node1 of Node3 is not completed. Location: GraphNode.check_parent_status\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,032 - INFO ==> Thread started for node: Node3 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,033 - INFO ==> Running node: Node1. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,033 - INFO ==> Thread started for node: Node1 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;33m2025-05-15 14:48:01,034 - WARNING ==> Parent node Node1 of Node2 is not completed. Location: GraphNode.check_parent_status\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,035 - INFO ==> Thread started for node: Node2 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;36m2025-05-15 14:48:01,072 - DEBUG ==> Subprocess output: {\"output1\": 22, \"output2\": 100}\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,073 - INFO ==> Completed node: Node1 with result: {'output1': '22', 'output2': '100'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;33m2025-05-15 14:48:01,073 - WARNING ==> Parent node Node2 of Node3 is not completed. Location: GraphNode.check_parent_status\u001b[0m\n",
      "\u001b[1;36m2025-05-15 14:48:01,074 - DEBUG ==> Notifying child node: Node2 . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:01,074 - INFO ==> Running node: Node2. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;36m2025-05-15 14:48:06,103 - DEBUG ==> Subprocess output: {\"output1\": 63, \"output2\": 902}\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:06,105 - INFO ==> Completed node: Node2 with result: {'output1': '63', 'output2': '902'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;36m2025-05-15 14:48:06,105 - DEBUG ==> Notifying child node: Node3 . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:06,105 - INFO ==> Running node: Node3. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:06,106 - INFO ==> Completed node: Node3 with result: {'output1': 'LLM/Write summary of 22 = 10 + 12 and 63 = 22 + 41'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:06,106 - INFO ==> Execution completed for all nodes. Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;32m2025-05-15 14:48:06,108 - INFO ==> Graph saved to ./saved_graphs/graph_c10870e23ea1d1e7253ca8e586fb4a6a5fcfc497876ded26f3d141dc61047a18.json. Location: Graph.save_graph\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loaded_graph.execute_from_node(\"Node1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "79afa406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_graph.nodePool[\"Node1\"].status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239dd2a2",
   "metadata": {},
   "source": [
    "## Graph Session Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "7d9072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSessionManager:\n",
    "    def __init__(self, session_root_dir, timeout=10):\n",
    "        self.timeout = timeout\n",
    "\n",
    "        self.session_keys = os.listdir(session_root_dir)\n",
    "        self.session_metadata = {}\n",
    "        \n",
    "        for session_key in self.session_keys:\n",
    "            self.session_metadata[session_key] = {\n",
    "                'session_id': session_key,\n",
    "                'graph': None,\n",
    "                'created_at': time.time(),\n",
    "                'updated_at': time.time(),\n",
    "            }\n",
    "            self.session_metadata[session_key]['graph'] = self.load_graph_into_session(session_key)\n",
    "            \n",
    "    def load_graph_into_session(self, session_key):\n",
    "        graph = Graph(timeout=self.timeout, venv_path=None, create_env=None, python_packages=None, save_dir=f\"./saved_graphs/{session_key}/\")\n",
    "        print(f\"Loading graph from {session_key}\")\n",
    "        graph.load_graph()\n",
    "        return graph\n",
    "    \n",
    "    def create_session(self, session_id, venv_path, create_env, python_packages):\n",
    "        if session_id in self.session_metadata:\n",
    "            raise ValueError(f\"Session with ID {session_id} already exists.\")\n",
    "        \n",
    "        ############# Create a new graph and save it to the session directory\n",
    "        graph = Graph(timeout=self.timeout, venv_path=venv_path, create_env=create_env, python_packages=python_packages, save_dir=f\"./saved_graphs/{session_id}/\")\n",
    "        os.makedirs(os.path.join(\"./saved_graphs/\", session_id), exist_ok=True)\n",
    "        graph.compile()\n",
    "        \n",
    "        self.session_metadata[session_id] = {\n",
    "            'session_id': session_id,\n",
    "            'graph': graph,\n",
    "            'created_at': time.time(),\n",
    "            'updated_at': time.time(),\n",
    "        }\n",
    "        return graph\n",
    "    \n",
    "    def add_input_to_session(self, session_id, inputFields):\n",
    "        if session_id not in self.session_metadata:\n",
    "            raise ValueError(f\"Session with ID {session_id} does not exist.\")\n",
    "        \n",
    "        graph = self.session_metadata[session_id]['graph']\n",
    "        new_node = graph.addInput(inputFields)\n",
    "        graph.compile()\n",
    "        return new_node\n",
    "    \n",
    "    def add_node_to_session(self, session_id, nodeName, systemInstructions, userPrompt, pythonCode, outputSchema, **kwargs):\n",
    "        if session_id not in self.session_metadata:\n",
    "            raise ValueError(f\"Session with ID {session_id} does not exist.\")\n",
    "        \n",
    "        graph = self.session_metadata[session_id]['graph']\n",
    "        new_node = graph.addNode(nodeName, systemInstructions, userPrompt, pythonCode, outputSchema, **kwargs)\n",
    "        graph.compile()\n",
    "        return new_node\n",
    "    \n",
    "    def execute_session(self, session_id, start_node):\n",
    "        if session_id not in self.session_metadata:\n",
    "            raise ValueError(f\"Session with ID {session_id} does not exist.\")\n",
    "        \n",
    "        graph = self.session_metadata[session_id]['graph']\n",
    "        graph.execute_from_node(start_node)\n",
    "        return graph\n",
    "    \n",
    "    def get_session_graph(self, session_id):\n",
    "        if session_id not in self.session_metadata:\n",
    "            raise ValueError(f\"Session with ID {session_id} does not exist.\")\n",
    "        \n",
    "        return self.session_metadata[session_id]['graph']\n",
    "    \n",
    "    def delete_session(self, session_id):\n",
    "        if session_id not in self.session_metadata:\n",
    "            raise ValueError(f\"Session with ID {session_id} does not exist.\")\n",
    "        \n",
    "        del self.session_metadata[session_id]\n",
    "        LOGGER.info(f\"Session {session_id} deleted.\")\n",
    "        session_dir = os.path.join(\"./saved_graphs/\", session_id)\n",
    "        if os.path.exists(session_dir):\n",
    "            shutil.rmtree(session_dir)\n",
    "            LOGGER.info(f\"Session directory {session_dir} deleted.\")\n",
    "        else:\n",
    "            LOGGER.warning(f\"Session directory {session_dir} does not exist.\")\n",
    "        return True\n",
    "    \n",
    "    def list_sessions(self):\n",
    "        return list(self.session_metadata.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "e2b35014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 17:26:38,458 - INFO ==> Using Python from virtual environment: ./runner_envs/venv/bin/python\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from sample_session\n",
      "Requirement already satisfied: numpy in ./runner_envs/venv/lib/python3.9/site-packages (2.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/debasmitroy/Desktop/programming/ddruk-lz-0/agent-dag-builder/runner_envs/venv/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[1;32m2025-05-15 17:26:38,698 - INFO ==> Installed dependencies: ['numpy']\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:26:38,699 - INFO ==> Graph loaded from ./saved_graphs/sample_session/graph.json. Location: Graph.load_graph\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:26:38,699 - INFO ==> Graph compiled with ID: c10870e23ea1d1e7253ca8e586fb4a6a5fcfc497876ded26f3d141dc61047a18. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:26:38,700 - INFO ==> Graph saved to ./saved_graphs/sample_session/graph.json. Location: Graph.save_graph\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:26:38,701 - INFO ==> Graph compiled after loading from ./saved_graphs/sample_session/graph.json. Location: Graph.load_graph\u001b[0m\n",
      "\u001b[1;31m2025-05-15 17:26:38,701 - ERROR ==> Error loading graph: [Errno 20] Not a directory: './saved_graphs/graph.json/graph.json'. Location: Graph.load_graph\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from graph.json\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: './saved_graphs/graph.json/graph.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[644], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m session_manager \u001b[38;5;241m=\u001b[39m \u001b[43mGraphSessionManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_root_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./saved_graphs/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[643], line 15\u001b[0m, in \u001b[0;36mGraphSessionManager.__init__\u001b[0;34m(self, session_root_dir, timeout)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m session_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_keys:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_metadata[session_key] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m'\u001b[39m: session_key,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m: time\u001b[38;5;241m.\u001b[39mtime(),\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_at\u001b[39m\u001b[38;5;124m'\u001b[39m: time\u001b[38;5;241m.\u001b[39mtime(),\n\u001b[1;32m     14\u001b[0m     }\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_metadata[session_key][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_graph_into_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[643], line 20\u001b[0m, in \u001b[0;36mGraphSessionManager.load_graph_into_session\u001b[0;34m(self, session_key)\u001b[0m\n\u001b[1;32m     18\u001b[0m graph \u001b[38;5;241m=\u001b[39m Graph(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, venv_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, python_packages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saved_graphs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading graph from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph\n",
      "Cell \u001b[0;32mIn[640], line 211\u001b[0m, in \u001b[0;36mGraph.load_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    212\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m node_name, node_data \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Desktop/programming/ddruk-lz-0/agent-dag-builder/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: './saved_graphs/graph.json/graph.json'"
     ]
    }
   ],
   "source": [
    "session_manager = GraphSessionManager(session_root_dir=\"./saved_graphs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "72b8f063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_manager.list_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "48019046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2025-05-15 17:03:58,013 - WARNING ==> Virtual environment already exists at ./runner_envs/venv. Skipping creation.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:03:58,015 - INFO ==> Using Python from virtual environment: ./runner_envs/venv/bin/python\u001b[0m\n",
      "WARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/debasmitroy/Desktop/programming/ddruk-lz-0/agent-dag-builder/runner_envs/venv/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[1;32m2025-05-15 17:03:58,343 - INFO ==> Installed dependencies: ['numpy']\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:03:58,344 - INFO ==> Graph compiled with ID: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:03:58,344 - INFO ==> Graph saved to ./saved_graphs/sample_session/graph.json. Location: Graph.save_graph\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./runner_envs/venv/lib/python3.9/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "sample_graph = session_manager.create_session(session_id=\"sample_session\", \n",
    "                                              venv_path=\"./runner_envs/venv\", \n",
    "                                              create_env=True, \n",
    "                                              python_packages=[\"numpy\"]\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "296479e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 17:04:05,325 - INFO ==> Graph compiled with ID: 69437e07646e7665bd8f52a097bdcf7c4781965b07b3265a85bff1c9c9710111. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:05,326 - INFO ==> Graph saved to ./saved_graphs/sample_session/graph.json. Location: Graph.save_graph\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:05,326 - INFO ==> Graph compiled with ID: b59535467f2679f21c6d7a0e24ffc6a90652f5a6fd7d970b1cb71bfe0aa65450. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:05,327 - INFO ==> Graph saved to ./saved_graphs/sample_session/graph.json. Location: Graph.save_graph\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:05,327 - INFO ==> Graph compiled with ID: 2fd39d19cb1b3c8253ece592983efe2fb5f515a17b7550963ae60b6e278519f3. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:05,327 - INFO ==> Graph saved to ./saved_graphs/sample_session/graph.json. Location: Graph.save_graph\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:05,328 - INFO ==> Graph compiled with ID: c10870e23ea1d1e7253ca8e586fb4a6a5fcfc497876ded26f3d141dc61047a18. Location: Graph.compile\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:05,328 - INFO ==> Graph saved to ./saved_graphs/sample_session/graph.json. Location: Graph.save_graph\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GraphNode at 0x1181aedc0>"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_manager.add_input_to_session(\n",
    "    session_id=\"sample_session\",\n",
    "    inputFields=inputs\n",
    ")\n",
    "\n",
    "session_manager.add_node_to_session(\n",
    "    session_id=\"sample_session\",\n",
    "    nodeName=node1.nodeName,\n",
    "    systemInstructions=node1.systemInstructions,\n",
    "    userPrompt=node1.userPrompt,\n",
    "    pythonCode=node1.pythonCode,\n",
    "    outputSchema=node1.outputSchema\n",
    ")\n",
    "session_manager.add_node_to_session(\n",
    "    session_id=\"sample_session\",\n",
    "    nodeName=node2.nodeName,\n",
    "    systemInstructions=node2.systemInstructions,\n",
    "    userPrompt=node2.userPrompt,\n",
    "    pythonCode=node2.pythonCode,\n",
    "    outputSchema=node2.outputSchema\n",
    ")\n",
    "session_manager.add_node_to_session(\n",
    "    session_id=\"sample_session\",\n",
    "    nodeName=node3.nodeName,\n",
    "    systemInstructions=node3.systemInstructions,\n",
    "    userPrompt=node3.userPrompt,\n",
    "    pythonCode=node3.pythonCode,\n",
    "    outputSchema=node3.outputSchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "6c8c6e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-05-15 17:04:29,350 - INFO ==> Node Node3 status set to pending.\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:29,351 - INFO ==> Node Node2 status set to pending.\u001b[0m\n",
      "\u001b[1;33m2025-05-15 17:04:29,352 - WARNING ==> Parent node Node2 of Node3 is not completed. Location: GraphNode.check_parent_status\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:29,353 - INFO ==> Thread started for node: Node3 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:29,354 - INFO ==> Running node: Node2. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:29,355 - INFO ==> Thread started for node: Node2 . Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;36m2025-05-15 17:04:34,388 - DEBUG ==> Subprocess output: {\"output1\": 63, \"output2\": 902}\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:34,389 - INFO ==> Completed node: Node2 with result: {'output1': '63', 'output2': '902'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;36m2025-05-15 17:04:34,389 - DEBUG ==> Notifying child node: Node3 . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:34,389 - INFO ==> Running node: Node3. Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:34,389 - INFO ==> Completed node: Node3 with result: {'output1': 'LLM/Write summary of 22 = 10 + 12 and 63 = 22 + 41'} . Location: Graph._execute_node_with_condition\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:34,390 - INFO ==> Execution completed for all nodes. Location: Graph.execute_from_node\u001b[0m\n",
      "\u001b[1;32m2025-05-15 17:04:34,391 - INFO ==> Graph saved to ./saved_graphs/sample_session/graph.json. Location: Graph.save_graph\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Graph at 0x11837fc70>"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_manager.execute_session(\n",
    "    session_id=\"sample_session\",\n",
    "    start_node=\"Node2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34296d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
